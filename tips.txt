1- set proxy in /etc/systemd/system/docker.service.d/proxy.conf
2- git clone https://github.com/s-ali-miri/ELK-with-docker.git
3- cd ELK-with-docker/
3.1- go to docker-compose.yml, in setup container, add your IP or domain_name in the instances.yml which is created in the setup container
4- docker compose up -d
4.1- if kibana did not become healthy and you in the logs you see can not authenticate kibana_system, go into es01 container and reset the password for kibana_system (/usr/share/elasticsearch/bin/elasticsearch-reset-password -i -u kibana_system --url https://es01:9200)
5- go to https://IP and elastic is ready! (not completely :D)
6- go to Fleet>Setting>edit output and change the "http://localhost:9200" to "https://IP:9200"
7- use this command (in the linux terminal) to get finger print of ca.crt
openssl x509 -fingerprint -sha256 -noout -in /path/to/ca.crt | awk -F"=" {' print $2 '} | sed s/://g
then copy paste the result into "Elasticsearch CA trusted fingerprint (optional)" in Kibana
8- also cat the ca.crt and copy the result in "Advanced YAML configuration"(fleet>settings>Output) like this:(mind spaces)
ssl:
  certificate_authorities:
    - |
      -----BEGIN CERTIFICATE-----
	CERT
      -----END CERTIFICATE-----

# if you need to collect logs from CUSTOM APP (you can find integration for most of famous apps, i.e fortinet, aws, etc.)
9.1- add this to docker-compose.yml (without #)
#  logstash01:
#    depends_on:
#      es01:
#        condition: service_healthy
#      kibana:
#        condition: service_healthy
#    image: docker.elastic.co/logstash/logstash:${STACK_VERSION}
#    restart: unless-stopped
#    mem_limit: ${LS_MEM_LIMIT} # you can add this variable to .env or configure it manualy here
#    labels:
#      co.elastic.logs/module: logstash
#    user: root
#    ports:
#      - "517:517/udp" # or any other port
#    volumes:
#      - ./certs:/usr/share/logstash/certs
#      - logstashdata01:/usr/share/logstash/data
#      - "./logstash_ingest_data/:/usr/share/logstash/ingest_data/"
#      - "./logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro"
#    environment:
#      - xpack.monitoring.enabled=false
#      - ELASTIC_USER=elastic
#      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
#      - ELASTIC_HOSTS=https://IP:9200

9.2- then you need to define grok pattern for your logs(https://edgedelta.com/company/blog/what-are-grok-patterns)

# if your network is air-gapped and you need to have local package-registry
10- docker pull docker.elastic.co/package-registry/distribution:8.19.3
11- docker save -o package-registry-8.19.3.tar docker.elastic.co/package-registry/distribution:8.19.3
12- move the package-registry-8.19.3.tar to ELK server
13- docker load -i package-registry-8.19.3.tar (on the ELK server)
14- docker run -it -p 8080:8080 docker.elastic.co/package-registry/distribution:8.19.3 (or add it in docker compose)
15- add this line under kibana, in environment section in docker-compose.yml:
      - XPACK_FLEET_REGISTRYURL="http://IP or hostname:8080"


